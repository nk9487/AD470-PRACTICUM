{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#steps\n",
    "\n",
    "#separate the training data and validation data\n",
    "#1. separate training and validation data sets into folder.\n",
    "#2.set directories to the file\n",
    "#3.create image layer for all that includes their pixel and color format\n",
    "#4.Create deep learing model using Keras API(Namuna)\n",
    "\n",
    "##Dipendra\n",
    "#5. compile model \n",
    "#6. sets up the data generators for loading and preprocessing images for training and validation in a deep learning model.\n",
    "#7. train the deep learning model using the fit_generator() method from the Keras API.\n",
    "\n",
    "##Jeffrey\n",
    "#8. save model\n",
    "#9. optional create a function that calculates accuracy of model based on validation data.\n",
    "#10. create a function that loads the validation data to the model we create and generate a CSV file of the result.(Jeffrey)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "##1 setting directory\n",
    "\n",
    "import os\n",
    "\n",
    "#base directory: replace it with the base directory of yours\n",
    "base_dir = 'C:\\\\Users\\\\namun\\\\AD-470 PRACTICUM LOCAL\\\\real-or-ai'\n",
    "\n",
    "#train and validation directory\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')#test \n",
    "validate_real= os.path.join(base_dir, 'real')\n",
    "validate_ai = os.path.join(base_dir, 'ai')\n",
    "\n",
    "\n",
    "# Directory with our training ai pictures\n",
    "train_ai_dir = os.path.join(train_dir, 'ai')\n",
    "\n",
    "# Directory with our training real pictures\n",
    "train_real_dir = os.path.join(train_dir, 'real')\n",
    "\n",
    "#print('total validation  images:', len(os.listdir(validation_dir)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##2\n",
    "\n",
    "train_real_fnames = os.listdir(train_real_dir)\n",
    "train_real_fnames.sort()\n",
    "#print(train_real_fnames[:5])\n",
    "\n",
    "train_ai_fnames = os.listdir(train_ai_dir)\n",
    "train_ai_fnames.sort()\n",
    "#print(train_ai_fnames[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##3 \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "# Our input feature map is 150x150x3: 150x150 for the image pixels, and 3 for\n",
    "# the three color channels: R, G, and B\n",
    "\n",
    "img_input = layers.Input(shape=(150, 150, 3))\n",
    "\n",
    "# First convolution extracts 16 filters that are 3x3\n",
    "# Convolution is followed by max-pooling layer with a 2x2 window\n",
    "x = layers.Conv2D(16, 3, activation='relu')(img_input)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "\n",
    "# Second convolution extracts 32 filters that are 3x3\n",
    "# Convolution is followed by max-pooling layer with a 2x2 window\n",
    "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "\n",
    "# Third convolution extracts 64 filters that are 3x3\n",
    "# Convolution is followed by max-pooling layer with a 2x2 window\n",
    "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "\n",
    "# Fourth convolution extracts 128 filters that are 3x3\n",
    "# Convolution is followed by max-pooling layer with a 2x2 window\n",
    "x = layers.Conv2D(128, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 148, 148, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 74, 74, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 72, 72, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 34, 34, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 3,309,729\n",
      "Trainable params: 3,309,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "##4\n",
    "\n",
    "# Flatten feature map to a 1-dim tensor so we can add fully connected layers\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "# Create a fully connected layer with ReLU activation and 512 hidden units\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "# Create output layer with a single node and sigmoid activation\n",
    "output = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Create model:\n",
    "# input = input feature map\n",
    "# output = input feature map + stacked convolution/maxpooling layers + fully \n",
    "# connected layer + sigmoid output layer\n",
    "model = Model(img_input, output)\n",
    "\n",
    "#uncooment for summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#5\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(lr=0.001),\n",
    "\n",
    "              metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 56783 images belonging to 2 classes.\n",
      "Found 4000 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "#6\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# All images will be rescaled by 1./255\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,  # This is the source directory for training images\n",
    "        target_size=(150, 150),  # All images will be resized to 150x150\n",
    "        batch_size=20,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary')\n",
    "\n",
    "# Flow validation images in batches of 20 using val_datagen generator\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-c109d934bbe1>:8: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 100 steps, validate for 50 steps\n",
      "Epoch 1/2\n",
      "100/100 - 102s - loss: 0.2862 - acc: 0.9145 - val_loss: 18.8965 - val_acc: 0.0200\n",
      "Epoch 2/2\n",
      "100/100 - 89s - loss: 0.3483 - acc: 0.9880 - val_loss: 15.3663 - val_acc: 0.0440\n"
     ]
    }
   ],
   "source": [
    "#7\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,  # 2000 images = batch_size * steps\n",
    "      epochs=2,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50,  # 1000 images = batch_size * steps\n",
    "      verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8 \n",
    "model.save(\"real-or-ai.h5\") #by default this will save it under current note book file directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9 create a function that calculates accuracy of model based on validation data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10 \n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model(\"C:\\\\Users\\\\namun\\\\AD-470 PRACTICUM LOCAL\")\n",
    "\n",
    "# Define the directory containing the test images\n",
    "test_dir = 'C:\\\\Users\\\\namun\\\\AD-470 PRACTICUM LOCAL\\\\real-or-ai\\\\validation\\\\validation'\n",
    "\n",
    "# Get a list of the image file names in the directory\n",
    "image_filenames = os.listdir(test_dir)\n",
    "\n",
    "# Create an empty list to store the predictions\n",
    "predictions = []\n",
    "\n",
    "# Loop over each image file in the directory\n",
    "for image_filename in image_filenames:\n",
    "    # Load the image file\n",
    "    image = load_img(os.path.join(test_dir, image_filename), target_size=(150, 150))\n",
    "    \n",
    "    # Convert the image to a NumPy array\n",
    "    image_array = img_to_array(image) / 255.\n",
    "    \n",
    "    # Add a batch dimension to the array\n",
    "    image_array = image_array.reshape((1, 150, 150, 3))\n",
    "    \n",
    "    # Make a prediction on the image\n",
    "    prediction = model.predict(image_array)[0][0]\n",
    "    \n",
    "    # Append the prediction to the list\n",
    "    predictions.append((image_filename.split('.')[0], 'real' if prediction > 0.5 else 'ai'))\n",
    "\n",
    "# Create a DataFrame from the predictions list\n",
    "df = pd.DataFrame(predictions, columns=['id', 'class'])\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "df.to_csv('real-or-ai-predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-34-ed636199ab64>\", line 47, in <module>\n",
      "    calculate_accuracy(validate_real,model)\n",
      "  File \"<ipython-input-34-ed636199ab64>\", line 30, in calculate_accuracy\n",
      "    preprocessed_images = preprocess_images(images)\n",
      "  File \"<ipython-input-34-ed636199ab64>\", line 13, in preprocess_images\n",
      "    image = load_img(image_filename, target_size=(150, 150))\n",
      "  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\utils.py\", line 113, in load_img\n",
      "    with open(path, 'rb') as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'C'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2040, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'FileNotFoundError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 965, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "#Adding a function that can determine accuracy since the project was closed\n",
    "import tensorflow as tf\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import os\n",
    "\n",
    "# Preprocess the images\n",
    "def preprocess_images(images):\n",
    "    preprocessed_images = []\n",
    "    \n",
    "    for image_filename in images:\n",
    "        # Load the image file\n",
    "        image = load_img(image_filename, target_size=(150, 150))\n",
    "        \n",
    "        # Convert the image to a NumPy array\n",
    "        image_array = img_to_array(image) / 255.\n",
    "        \n",
    "        # Add a batch dimension to the array\n",
    "        image_array = image_array.reshape((1, 150, 150, 3))\n",
    "        \n",
    "        preprocessed_images.append(image_array)\n",
    "    \n",
    "    return preprocessed_images\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calculate_accuracy(images, model):\n",
    "    # Preprocess the images\n",
    "    preprocessed_images = preprocess_images(images)\n",
    "    \n",
    "    # Make predictions using the model\n",
    "    predictions = model.predict(preprocessed_images)\n",
    "    \n",
    "    # Calculate the accuracy\n",
    "    num_correct = 0\n",
    "    num_total = len(images)\n",
    "    \n",
    "    for i in range(len(images)):\n",
    "        if predictions[i] == images[i].label:\n",
    "            num_correct += 1\n",
    "    \n",
    "    accuracy = (num_correct / num_total) * 100\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "calculate_accuracy(validate_real,model)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2e7b1d15100c9772277e2b4b8b99a8bb6cf88c4c06e0444c3999d6c521403cc4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
