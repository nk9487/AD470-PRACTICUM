{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#steps\n",
    "#separate the training data and validation data\n",
    "#1. separate training and validation data sets into folder.\n",
    "#2.set directories to the file\n",
    "#3.create image layer for all that includes their pixel and color format\n",
    "#4.Create deep learing model using Keras API\n",
    "#5. compile model \n",
    "#6. sets up the data generators for loading and preprocessing images for training and validation in a deep learning model.\n",
    "#7. train the deep learning model using the fit_generator() method from the Keras API.\n",
    "#8. save model\n",
    "#9. optional create a function that calculates accuracy of model based on validation data.\n",
    "#10. create a function that loads the validation data to the model we create and generate a CSV file of the result.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##1 setting directory\n",
    "\n",
    "import os\n",
    "\n",
    "#base directory: replace it with the base directory of yours\n",
    "base_dir = 'C:\\\\Users\\\\namun\\\\AD-470 PRACTICUM\\\\real-or-ai'\n",
    "\n",
    "#train and validation directory\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')#test \n",
    "\n",
    "\n",
    "# Directory with our training ai pictures\n",
    "train_ai_dir = os.path.join(train_dir, 'ai')\n",
    "\n",
    "# Directory with our training real pictures\n",
    "train_real_dir = os.path.join(train_dir, 'real')\n",
    "\n",
    "#print('total validation  images:', len(os.listdir(validation_dir)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##2\n",
    "\n",
    "train_real_fnames = os.listdir(train_real_dir)\n",
    "train_real_fnames.sort()\n",
    "#print(train_real_fnames[:5])\n",
    "\n",
    "train_ai_fnames = os.listdir(train_ai_dir)\n",
    "train_ai_fnames.sort()\n",
    "#print(train_ai_fnames[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##3\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "# Our input feature map is 150x150x3: 150x150 for the image pixels, and 3 for\n",
    "# the three color channels: R, G, and B\n",
    "img_input = layers.Input(shape=(150, 150, 3))\n",
    "\n",
    "# First convolution extracts 16 filters that are 3x3\n",
    "# Convolution is followed by max-pooling layer with a 2x2 window\n",
    "x = layers.Conv2D(16, 3, activation='relu')(img_input)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "\n",
    "# Second convolution extracts 32 filters that are 3x3\n",
    "# Convolution is followed by max-pooling layer with a 2x2 window\n",
    "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "\n",
    "# Third convolution extracts 64 filters that are 3x3\n",
    "# Convolution is followed by max-pooling layer with a 2x2 window\n",
    "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4\n",
    "# Flatten feature map to a 1-dim tensor so we can add fully connected layers\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "# Create a fully connected layer with ReLU activation and 512 hidden units\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "# Create output layer with a single node and sigmoid activation\n",
    "output = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Create model:\n",
    "# input = input feature map\n",
    "# output = input feature map + stacked convolution/maxpooling layers + fully \n",
    "# connected layer + sigmoid output layer\n",
    "model = Model(img_input, output)\n",
    "\n",
    "#uncooment for summary\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(lr=0.001),\n",
    "\n",
    "              metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 56783 images belonging to 2 classes.\n",
      "Found 4000 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "#6\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# All images will be rescaled by 1./255\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,  # This is the source directory for training images\n",
    "        target_size=(150, 150),  # All images will be resized to 150x150\n",
    "        batch_size=20,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary')\n",
    "\n",
    "# Flow validation images in batches of 20 using val_datagen generator\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-15-c109d934bbe1>:8: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-15-c109d934bbe1>:8: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 100 steps, validate for 50 steps\n",
      "Epoch 1/2\n",
      "100/100 - 99s - loss: 0.3448 - acc: 0.9170 - val_loss: 18.0435 - val_acc: 0.0240\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-15-c109d934bbe1>\", line 8, in <module>\n",
      "    verbose=2)\n",
      "  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 324, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 1306, in fit_generator\n",
      "    initial_epoch=initial_epoch)\n",
      "  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 819, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\", line 342, in fit\n",
      "    total_epochs=epochs)\n",
      "  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\", line 128, in run_one_epoch\n",
      "    batch_outs = execution_function(iterator)\n",
      "  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\", line 98, in execution_function\n",
      "    distributed_function(input_fn))\n",
      "  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 568, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 599, in _call\n",
      "    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\n",
      "  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 2363, in __call__\n",
      "    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\n",
      "  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 1611, in _filtered_call\n",
      "    self.captured_inputs)\n",
      "  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 1692, in _call_flat\n",
      "    ctx, args, cancellation_manager=cancellation_manager))\n",
      "  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 545, in call\n",
      "    ctx=ctx)\n",
      "  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\", line 67, in quick_execute\n",
      "    six.raise_from(core._status_to_exception(e.code, message), None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "tensorflow.python.framework.errors_impl.UnknownError:  OSError: unrecognized data stream contents when reading image file\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\script_ops.py\", line 236, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\", line 789, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\data_adapter.py\", line 975, in generator_fn\n",
      "    yield x[i]\n",
      "\n",
      "  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 65, in __getitem__\n",
      "    return self._get_batches_of_transformed_samples(index_array)\n",
      "\n",
      "  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 230, in _get_batches_of_transformed_samples\n",
      "    interpolation=self.interpolation)\n",
      "\n",
      "  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\utils.py\", line 138, in load_img\n",
      "    img = img.resize(width_height_tuple, resample)\n",
      "\n",
      "  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\PIL\\Image.py\", line 1886, in resize\n",
      "    self.load()\n",
      "\n",
      "  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\PIL\\ImageFile.py\", line 272, in load\n",
      "    raise_ioerror(err_code)\n",
      "\n",
      "  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\PIL\\ImageFile.py\", line 59, in raise_ioerror\n",
      "    raise IOError(message + \" when reading image file\")\n",
      "\n",
      "OSError: unrecognized data stream contents when reading image file\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "\t [[IteratorGetNext]] [Op:__inference_distributed_function_1249]\n",
      "\n",
      "Function call stack:\n",
      "distributed_function\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2040, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'UnknownError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 965, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": " OSError: unrecognized data stream contents when reading image file\nTraceback (most recent call last):\n\n  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\script_ops.py\", line 236, in __call__\n    ret = func(*args)\n\n  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\", line 789, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\data_adapter.py\", line 975, in generator_fn\n    yield x[i]\n\n  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 65, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 230, in _get_batches_of_transformed_samples\n    interpolation=self.interpolation)\n\n  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\utils.py\", line 138, in load_img\n    img = img.resize(width_height_tuple, resample)\n\n  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\PIL\\Image.py\", line 1886, in resize\n    self.load()\n\n  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\PIL\\ImageFile.py\", line 272, in load\n    raise_ioerror(err_code)\n\n  File \"c:\\Users\\namun\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\PIL\\ImageFile.py\", line 59, in raise_ioerror\n    raise IOError(message + \" when reading image file\")\n\nOSError: unrecognized data stream contents when reading image file\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_distributed_function_1249]\n\nFunction call stack:\ndistributed_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "#7\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,  # 2000 images = batch_size * steps\n",
    "      epochs=2,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50,  # 1000 images = batch_size * steps\n",
    "      verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8 \n",
    "model.save(\"real-or-ai.h5\") #by default this will save it under current note book file directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9 create a function that calculates accuracy of model based on validation data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10 \n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model(\"C:\\\\Users\\\\namun\\\\AD-470 PRACTICUM\")\n",
    "\n",
    "# Define the directory containing the test images\n",
    "test_dir = 'C:\\\\Users\\\\namun\\\\AD-470 PRACTICUM\\\\real-or-ai\\\\validation\\\\validation'\n",
    "\n",
    "# Get a list of the image file names in the directory\n",
    "image_filenames = os.listdir(test_dir)\n",
    "\n",
    "# Create an empty list to store the predictions\n",
    "predictions = []\n",
    "\n",
    "# Loop over each image file in the directory\n",
    "for image_filename in image_filenames:\n",
    "    # Load the image file\n",
    "    image = load_img(os.path.join(test_dir, image_filename), target_size=(150, 150))\n",
    "    \n",
    "    # Convert the image to a NumPy array\n",
    "    image_array = img_to_array(image) / 255.\n",
    "    \n",
    "    # Add a batch dimension to the array\n",
    "    image_array = image_array.reshape((1, 150, 150, 3))\n",
    "    \n",
    "    # Make a prediction on the image\n",
    "    prediction = model.predict(image_array)[0][0]\n",
    "    \n",
    "    # Append the prediction to the list\n",
    "    predictions.append((image_filename.split('.')[0], 'real' if prediction > 0.5 else 'ai'))\n",
    "\n",
    "# Create a DataFrame from the predictions list\n",
    "df = pd.DataFrame(predictions, columns=['id', 'class'])\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "df.to_csv('real-or-ai-predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2e7b1d15100c9772277e2b4b8b99a8bb6cf88c4c06e0444c3999d6c521403cc4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
